{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '/subscriptions/0b3f04a9-6375-4341-a513-dd53731a99a4/resourceGroups/dstoolkit-route-optimization/providers/Microsoft.MachineLearningServices/workspaces/amlrouteoptimization', 'name': 'amlrouteoptimization', 'identity': {'principal_id': '6a398b87-cd4d-4ff3-b66f-344edbdd9bd5', 'tenant_id': '72f988bf-86f1-41af-91ab-2d7cd011db47', 'type': 'SystemAssigned'}, 'location': 'australiaeast', 'type': 'Microsoft.MachineLearningServices/workspaces', 'tags': {}, 'sku': 'Basic', 'workspaceid': 'bb87308f-2811-4bdc-8c73-339822d22a39', 'sdkTelemetryAppInsightsKey': 'bd22fe07-ca7e-4337-bd98-3d5116261c1f', 'description': '', 'friendlyName': 'amlrouteoptimization', 'keyVault': '/subscriptions/0b3f04a9-6375-4341-a513-dd53731a99a4/resourceGroups/dstoolkit-route-optimization/providers/Microsoft.Keyvault/vaults/amlrouteoptimi7471905268', 'applicationInsights': '/subscriptions/0b3f04a9-6375-4341-a513-dd53731a99a4/resourceGroups/dstoolkit-route-optimization/providers/Microsoft.insights/components/amlrouteoptimi2935761665', 'storageAccount': '/subscriptions/0b3f04a9-6375-4341-a513-dd53731a99a4/resourceGroups/dstoolkit-route-optimization/providers/Microsoft.Storage/storageAccounts/amlrouteoptimi5805954762', 'hbiWorkspace': False, 'provisioningState': 'Succeeded', 'discoveryUrl': 'https://australiaeast.api.azureml.ms/discovery', 'notebookInfo': {'fqdn': 'ml-amlrouteo-australiaeast-bb87308f-2811-4bdc-8c73-339822d22a39.australiaeast.notebooks.azure.net', 'resource_id': 'aa86bebe303d4b4da13a8884ebae0c25'}, 'v1LegacyMode': False}\n"
     ]
    }
   ],
   "source": [
    "# Initilize Workspace\n",
    "\n",
    "ws_name = os.environ['AML_WORKSPACE_NAME']\n",
    "subscription_id = os.environ['AML_SUBSCRIPTION_ID']\n",
    "resource_group = os.environ['AML_RESOURCE_GROUP']\n",
    "tenant_id = os.environ['AML_TENANT_ID']\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)\n",
    "\n",
    "ws = Workspace(workspace_name=ws_name,\n",
    "                   subscription_id=subscription_id,\n",
    "                   resource_group=resource_group,\n",
    "                   auth=interactive_auth)\n",
    "\n",
    "print(ws.get_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new compute target\n",
      "InProgress.\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Retrieve or create an Aml compute\n",
    "min_nodes = int(os.environ['AML_MIN_NODES'])\n",
    "max_nodes = int(os.environ['AML_MAX_NODES'])\n",
    "\n",
    "aml_compute_target = os.environ['AML_COMPUTE_NAME']\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"creating new compute target\")\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = min_nodes, \n",
    "                                                                max_nodes = max_nodes)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Run Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source code is in ../src directory.\n"
     ]
    }
   ],
   "source": [
    "# Default datastore (Azure blob storage)\n",
    "def_blob_store = ws.get_default_datastore()\n",
    "\n",
    "# source directory\n",
    "source_directory = '../src'\n",
    "    \n",
    "print(f'Source code is in {source_directory} directory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# create a new runconfig object\n",
    "run_config = RunConfiguration()\n",
    "\n",
    "# environment\n",
    "env = Environment('op-env')\n",
    "\n",
    "# enable Docker \n",
    "env.docker.enabled = True\n",
    "# set Docker base image to the default CPU-based image\n",
    "env.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "env.python.user_managed_dependencies = False\n",
    "# specify CondaDependencies obj\n",
    "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['or-tools'])\n",
    "\n",
    "# set environment\n",
    "run_config.environment = env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Reduce the search space of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "# Model input\n",
    "order_file = os.environ['MODEL_INPUT_ORDER_FILE']\n",
    "distance_file = os.environ['MODEL_INPUT_DISTANCE_FILE']\n",
    "\n",
    "# List of packages to be delivered\n",
    "order = DataReference(\n",
    "    datastore=def_blob_store,\n",
    "    data_reference_name=\"order\",\n",
    "    path_on_datastore=order_file)\n",
    "\n",
    "# The pair-wise distance between cities\n",
    "distance = DataReference(\n",
    "    datastore=def_blob_store,\n",
    "    data_reference_name=\"distance\",\n",
    "    path_on_datastore=distance_file)\n",
    "\n",
    "# Naming the intermediate data \n",
    "model_result_partial = PipelineData(\"model_result_partial\",datastore=def_blob_store)\n",
    "model_input_reduced = PipelineData(\"model_input_reduced\",datastore=def_blob_store)\n",
    "\n",
    "reduce_step = PythonScriptStep(\n",
    "    script_name=\"reduce.py\", \n",
    "    arguments=[\"--order\", order, \"--distance\", distance, \"--model_result_partial\", model_result_partial, \"--model_input_reduced\", model_input_reduced],\n",
    "    inputs=[order, distance],\n",
    "    outputs=[model_result_partial, model_input_reduced],\n",
    "    compute_target=aml_compute, \n",
    "    source_directory=source_directory,\n",
    "    runconfig=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Partition the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the intermediate data \n",
    "model_input_list = PipelineData(\"model_input_list\",datastore=def_blob_store)\n",
    "\n",
    "parition_step = PythonScriptStep(\n",
    "    script_name=\"partiition.py\", \n",
    "    arguments=[\"--model_input_reduced\", model_input_reduced, \"--model_input_list\", model_input_list],\n",
    "    inputs=[model_input_reduced],\n",
    "    outputs=[model_input_list],\n",
    "    compute_target=aml_compute, \n",
    "    source_directory=source_directory,\n",
    "    runconfig=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Solve individual problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Step input must be of any type: dict_keys([<class 'azureml.data.tabular_dataset.TabularDataset'>, <class 'azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset'>, <class 'azureml.data.file_dataset.FileDataset'>, <class 'azureml.pipeline.core.pipeline_output_dataset.PipelineOutputFileDataset'>]), found <class 'azureml.pipeline.core.builder.PipelineData'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zhih\\Documents\\IP Development\\dstoolkit-route-optimization\\notebook\\aml_pipeline.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model_result_list \u001b[39m=\u001b[39m PipelineData(\u001b[39m\"\u001b[39m\u001b[39mmodel_result_list\u001b[39m\u001b[39m\"\u001b[39m,datastore\u001b[39m=\u001b[39mdef_blob_store)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m parallel_run_config \u001b[39m=\u001b[39m ParallelRunConfig(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     source_directory\u001b[39m=\u001b[39msource_directory,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     entry_script\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msolve.py\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     compute_target\u001b[39m=\u001b[39maml_compute,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     node_count\u001b[39m=\u001b[39mmax_nodes)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m solve_step \u001b[39m=\u001b[39m ParallelRunStep(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msolve\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     parallel_run_config\u001b[39m=\u001b[39;49mparallel_run_config,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     inputs\u001b[39m=\u001b[39;49m[model_input_list],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     output\u001b[39m=\u001b[39;49mmodel_result_list,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     allow_reuse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/zhih/Documents/IP%20Development/dstoolkit-route-optimization/notebook/aml_pipeline.ipynb#X25sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zhih\\Anaconda3\\envs\\optimization-ip\\lib\\site-packages\\azureml\\contrib\\pipeline\\steps\\parallel_run_step.py:239\u001b[0m, in \u001b[0;36mParallelRunStep.__init__\u001b[1;34m(self, name, parallel_run_config, inputs, output, side_inputs, models, arguments, allow_reuse, tags, properties, add_parallel_run_step_dependencies)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_glob_syntax_pattern \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m^\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39m$\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m}]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    237\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_module_logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m--> 239\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate()\n\u001b[0;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pystep_inputs()\n\u001b[0;32m    242\u001b[0m pipeline_runconfig_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipeline_runconfig_params()\n",
      "File \u001b[1;32mc:\\Users\\zhih\\Anaconda3\\envs\\optimization-ip\\lib\\site-packages\\azureml\\contrib\\pipeline\\steps\\parallel_run_step.py:269\u001b[0m, in \u001b[0;36mParallelRunStep._validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39m\"\"\"Validate input params to init parallel run step class.\"\"\"\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_name()\n\u001b[1;32m--> 269\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_inputs()\n\u001b[0;32m    270\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output()\n\u001b[0;32m    271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_parallel_run_config()\n",
      "File \u001b[1;32mc:\\Users\\zhih\\Anaconda3\\envs\\optimization-ip\\lib\\site-packages\\azureml\\contrib\\pipeline\\steps\\parallel_run_step.py:325\u001b[0m, in \u001b[0;36mParallelRunStep._validate_inputs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[39mreturn\u001b[39;00m ds_mapping_type\n\u001b[0;32m    322\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inputs, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inputs \u001b[39m!=\u001b[39m [], \\\n\u001b[0;32m    323\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThe parameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39minputs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a list and have at least one element.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 325\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_ds_type \u001b[39m=\u001b[39m _get_input_type(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inputs[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    326\u001b[0m \u001b[39mfor\u001b[39;00m input_ds \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inputs:\n\u001b[0;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_ds_type \u001b[39m!=\u001b[39m _get_input_type(input_ds):\n",
      "File \u001b[1;32mc:\\Users\\zhih\\Anaconda3\\envs\\optimization-ip\\lib\\site-packages\\azureml\\contrib\\pipeline\\steps\\parallel_run_step.py:317\u001b[0m, in \u001b[0;36mParallelRunStep._validate_inputs.<locals>._get_input_type\u001b[1;34m(in_ds)\u001b[0m\n\u001b[0;32m    315\u001b[0m     ds_mapping_type \u001b[39m=\u001b[39m INPUT_TYPE_DICT[input_type]\n\u001b[0;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[0;32m    318\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mStep input must be of any type: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, found \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(INPUT_TYPE_DICT\u001b[39m.\u001b[39mkeys(), input_type)\n\u001b[0;32m    319\u001b[0m     )\n\u001b[0;32m    320\u001b[0m \u001b[39mreturn\u001b[39;00m ds_mapping_type\n",
      "\u001b[1;31mException\u001b[0m: Step input must be of any type: dict_keys([<class 'azureml.data.tabular_dataset.TabularDataset'>, <class 'azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset'>, <class 'azureml.data.file_dataset.FileDataset'>, <class 'azureml.pipeline.core.pipeline_output_dataset.PipelineOutputFileDataset'>]), found <class 'azureml.pipeline.core.builder.PipelineData'>"
     ]
    }
   ],
   "source": [
    "from azureml.contrib.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
    "\n",
    "# Naming the intermediate data \n",
    "model_result_list = PipelineData(\"model_result_list\",datastore=def_blob_store)\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=source_directory,\n",
    "    entry_script='solve.py',\n",
    "    mini_batch_size=\"1\",\n",
    "    error_threshold=1,\n",
    "    output_action=\"append_row\",\n",
    "    environment=env,\n",
    "    compute_target=aml_compute,\n",
    "    node_count=max_nodes)\n",
    "\n",
    "solve_step = ParallelRunStep(\n",
    "    name=\"solve\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[model_input_list],\n",
    "    output=model_result_list,\n",
    "    allow_reuse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Merge the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the intermediate data \n",
    "model_result_final = PipelineData(\"model_result_final\",datastore=def_blob_store)\n",
    "\n",
    "merge_step = PythonScriptStep(\n",
    "    script_name=\"merge.py\", \n",
    "    arguments=[\"--model_input\", model_input, \"--model_result_partial\", model_result_partial, \"--model_result_list\", model_result_list, \"--model_result_final\", model_result_final],\n",
    "    inputs=[model_input, model_result_partial, model_result_list],\n",
    "    outputs=[model_result_final],\n",
    "    compute_target=aml_compute, \n",
    "    source_directory=source_directory,\n",
    "    runconfig=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[reduce_step, parition_step, solve_step, merge_step])\n",
    "print(\"Pipeline is built\")\n",
    "\n",
    "pipeline_run = Experiment(ws, 'optimization_example').submit(pipeline)\n",
    "print(\"Pipeline is submitted for execution\")\n",
    "\n",
    "RunDetails(pipeline_run).show()\n",
    "\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('optimization-ip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dc112f8eedd872ac4b4a310e5d0e2b86038880c45a5c41440f57bee5a6027e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
